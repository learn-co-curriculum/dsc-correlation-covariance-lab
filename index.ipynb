{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance and Correlation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you will work towards calculating covariance and correlation for a given dataset in python. You'll use the formulas shown in previous lesson and verify our results with python libraries.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Calculate and and interpret correlation and covariance for given variables\n",
    "* Build density and scatter plots to visually identify the level of dependence between variables\n",
    "* Perform covariance and correlation using python and numpy \n",
    "\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "Included dataset (heightWeight.csv) includes 20 heights (in inches) and weights (in pounds). Thia small dataset will help us focus more on seeing covariance and correlation in action!\n",
    "\n",
    "At this point, you should be able to calculate the average height and average weight. You can also explain the medians, variances and standard deviations for this dataset.\n",
    "\n",
    "But all of those measurements are only concerned with a **single variable**. In this lab, you'll answer the following questions:\n",
    "\n",
    "1. How does height interact with weight? \n",
    "2. Does weight increase as height increases?\n",
    "3. Are weight and height not related at all?\n",
    "\n",
    "There are always exceptions, but when you look at the population in general, taller people will tend to weigh more than shorter people. While you should *always* be cautious when generalizing, generalization of information can be very useful as it shows you a bigger picture that you can build your intuitions upon. This is also what a lot of core statistical principles are built upon.\n",
    "\n",
    "\n",
    "First, let's load this dataset in python using pandas. Next, print the length of the data, the head of the data, and the basic statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "   height  weight\n",
      "0      68     165\n",
      "1      71     201\n",
      "2      61     140\n",
      "3      69     170\n",
      "4      71     192\n",
      "          height      weight\n",
      "count  20.000000   20.000000\n",
      "mean   66.850000  165.800000\n",
      "std     5.112163   28.971129\n",
      "min    58.000000  115.000000\n",
      "25%    63.250000  143.750000\n",
      "50%    68.500000  170.000000\n",
      "75%    71.000000  192.750000\n",
      "max    74.000000  210.000000\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into pandas and perform basic inspection\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('heightweight.csv')\n",
    "\n",
    "print (len(data))\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Covariance \n",
    "\n",
    "Here's the covariance formula once again. \n",
    "\n",
    "$$cov(x,y) = \\frac{1}{n-1}\\displaystyle\\sum_{i=1}^{n}(x_i -\\bar x)(y_i - \\bar y)$$\n",
    "\n",
    "Note that we devide by $(n-1)$ here, because of the assumption that this particular data is a _sample of a bigger population_. The bigger population here could be the entire world population. When working with populations. The general rule is to divide by $n$. When working with a sample, you should divide by $n-1$. In practice, however, you'll see the two formulas are often being used interchangeably. \n",
    "\n",
    "### Mean Normalization \n",
    "\n",
    "Looking at the formula of covariance, you'll noticed that it is composed out of $(x_i -\\bar x)$ and $(y_i -\\bar y)$. These are also known as the **mean normalized** variables $x$ and $y$. The idea is that you take each element in $x$ and $y$ and respectively subtract the mean of $x$ and $y$. The result is that your \"altered\" x and y now have mean 0.\n",
    "\n",
    "So how do you do  this? You can write a function that takes in a vector, calculates the mean of this vector and subtracts the calculated mean value from each element to calculate $(x_i -\\bar x)$ and  $(y_i -\\bar y)$ . \n",
    "\n",
    "*Hint*: you can use `np.mean()` to calculate the mean for above formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-2.0, -1.0, 0.0, 1.0, 2.0], [-22.0, -11.0, 0.0, 11.0, 22.0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Write a function to take in an iterable, calculate the mean and subtract the mean value\n",
    "# from each element , creating and returning a new list. \n",
    "\n",
    "def mean_normalize(var):\n",
    "\n",
    "    norm = [] # Vector for storing output values \n",
    "    n = 0     # a counter to identify the position of next element in vector\n",
    "    mean = np.mean(var)\n",
    "    \n",
    "    # for each element in the vector, subtract from mean and add the result to norm\n",
    "    for i in var:\n",
    "        diff = var[n] - mean\n",
    "        norm.append(diff)\n",
    "        n = n + 1\n",
    "    \n",
    "    return norm\n",
    "\n",
    "mean_normalize([1,2,3,4,5]), mean_normalize([11,22,33,44,55])\n",
    "\n",
    "# ([-2.0, -1.0, 0.0, 1.0, 2.0], [-22.0, -11.0, 0.0, 11.0, 22.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You'll see that our function maintains the _variance_ of list elements and moves the mean to zero. As a quick test, you can visualize what exactly happens to the data with mean normalization. \n",
    "\n",
    "Use seaborn to plot the height variable distribution before and after the normalization process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Visualize the height data distribution before and after mean normalization \n",
    "\n",
    "height = mean_normalize(data.height)\n",
    "import seaborn as sns\n",
    "sns.distplot(data.height)\n",
    "sns.distplot(height);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go! The _shape_ of the data isn't changed, but the mean is just shifted! You can also try this for the weight variable.\n",
    "\n",
    "### The Dot Product\n",
    "Now that you have normalized the variables height and weight, you have to go ahead and take the _dot product_ of these two normalized variables.\n",
    "\n",
    "> A dot product is a linear algebraic operation that takes two equal-length sequences of numbers and returns a single number which can be used as a measure of similarity between these sequences (also known as vectors).\n",
    "\n",
    "[Here is a great article explaining this in detail](https://betterexplained.com/articles/vector-calculus-understanding-the-dot-product/).\n",
    "\n",
    "For two vectors a and b, a dot product is calculated by multiplying each element of one vector to its counterpart in the second, and then adding them up together. Imagive you want to take the dot product of two variables `a` and `b`:\n",
    "\n",
    "```\n",
    " a[0] * b[0] + a[1] * b[1] + a[2] * b[2] ...\n",
    "\n",
    "```\n",
    "\n",
    "Let's write a function that takes two iterables and return their dot product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function to calculate the dot product of two iterables \n",
    "\n",
    "def dot_product(x,y):\n",
    "    n = 0  # a counter pointing to the current element of vector(s)\n",
    "    prod_vec = [] # Initliaze an empty list to store the results \n",
    "    \n",
    "    # For all elements in the vectors, multiply and save results in prod_vec\n",
    "    for i in range(len(x)):\n",
    "        prod = x[i]* y[i]\n",
    "        prod_vec.append(prod)\n",
    "        n += 1\n",
    "        \n",
    "    dot_prod = np.sum(prod_vec)\n",
    "    return dot_prod\n",
    "\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "\n",
    "dot_product(a,b)\n",
    "\n",
    "#  32  calculated as (1*4 + 2*5 + 3*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the numerator of the formula sorted out, let's finally write a function `covariance()` that takes the height and weight lists created earlier and returns the covariance value using the functions you created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.75789473684208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate covariance using functions above\n",
    "\n",
    "def covariance(var1, var2):\n",
    "\n",
    "    # Formula for covariance is:\n",
    "    # [Sum (x_i - X)(y_i - Y)] / N-1 \n",
    "    \n",
    "    # Sanity Check : Check to see if both vectors are of same length\n",
    "    # Exit the function if variables have different lengths\n",
    "\n",
    "    if len(var1) != len(var2):\n",
    "        return None \n",
    "    else: \n",
    "       \n",
    "        # Mean normalize both variables \n",
    "        x = mean_normalize(var1)\n",
    "        y = mean_normalize(var2)\n",
    "        \n",
    "        # Take the dot product of mean normalized variables\n",
    "        result = dot_product(x,y)\n",
    "\n",
    "        # divide the dot product by n-1    \n",
    "        return result /((len(var1)) -1)\n",
    "\n",
    "covariance(data['height'], data['weight'])\n",
    "\n",
    "# 144.75789473684208"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now verify your results with pandas built in `DataFrame.cov()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>26.134211</td>\n",
       "      <td>144.757895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>144.757895</td>\n",
       "      <td>839.326316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            height      weight\n",
       "height   26.134211  144.757895\n",
       "weight  144.757895  839.326316"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that you don't just get one value but four. It's important to know that covariances (as well as correlations) are oftehn shown in matrix form. The covariance between height and weight is exactly what we calculated. The matrix also shows the covariance of a variable with itself on the diagonal. The off-diagonal values show the covariance value (which is the same value twice: the covariance between weight and height is the same as the covariance between height and weight). \n",
    "\n",
    "Remember that covariance is a metric that is hard to interpret. Let's dig a little deeper by visualizing height and weight on a scatter plot! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11adc27f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a scatter graph between height and weight to visually inspect the relationship \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(data.height, data.weight);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see there is quite a bit of positive relationship between the two, but a covariance value is a bit hard to interpret. So let's try calculating correlation. \n",
    "\n",
    "## Calculating the Correlation\n",
    "\n",
    "Once again, heres the formula to calculate the correlation. \n",
    "$$ r = \\frac{\\sum_{i=1}^{n}(x_i -\\bar x)(y_i - \\bar y)} {\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar x)^2 \\sum_{i=1}^{n}(y_i-\\bar y)^2}}$$\n",
    "There are a lot of mean normalizations going on here. Try to use all the above to create a new function `correlation()`, and use the function to create a correlation between weight and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Correlation between two variables using formula above\n",
    "import math\n",
    "def correlation(var1,var2):\n",
    "    \n",
    "    if len(var1) != len(var2):\n",
    "        return None \n",
    "    else: \n",
    "       \n",
    "        mean_norm_var1 = mean_normalize(var1)\n",
    "        mean_norm_var2 = mean_normalize(var2)\n",
    "        \n",
    "        # Try the numpy way for calculating doc product\n",
    "        var1_dot_var2 = [a * b for a, b in list(zip(mean_norm_var1, mean_norm_var2))]\n",
    "        \n",
    "        var1_squared = [i * i for i in mean_norm_var1]\n",
    "        var2_squared = [i * i for i in mean_norm_var2]\n",
    "        \n",
    "        return np.round(sum(var1_dot_var2) / math.sqrt(sum(var1_squared) * sum(var2_squared)), 2)\n",
    "\n",
    "correlation(data['height'], data['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation of .98, that's very close to 1! That means that there is clearlt a strong relationship between height and weight. At least, for this particular sample!  And there is a takeaway in this. sample size plays a major rule in determining the nature of a variable and its relationship with other variables. The set of 20 records we have seem to correlate highly, but if you look at 20 other people, you'll see that this result will be different. The correlation here will depend on the _sample_, and you'll see that this will differ more clearly when working with smaller samples.\n",
    "\n",
    "As a last check , let's use pandas `DataFrame.corr()` method to see how that works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0.9774</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        height  weight\n",
       "height  1.0000  0.9774\n",
       "weight  0.9774  1.0000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns another matrix. You can see that a correlation of a variable with itself is always equal to 1. The correlation between height and weight can be rounded off to our results. Great! Now you know how this works. \n",
    "\n",
    "## Summary \n",
    "\n",
    "In this lab you learned how to calculate the covariance and correlation between variables. You also looked at mean normalization and dot products. Finally, you learned how to calculate these measures using pandas built in methods. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
